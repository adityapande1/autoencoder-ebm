{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "\n",
    "# Imports\n",
    "\n",
    "Import all relevant dependencies\n",
    "_________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import plot_digits, plot_original_vs_encoded\n",
    "\n",
    "from models.autoencoder.autoencoder import  Autoencoder\n",
    "from models.ebm.energy_net import EnergyNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "\n",
    "# Load Autoencoder and EBM\n",
    "The best parameters are saved with the prefix 'best' in the checkpoints folder\n",
    "_________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Autoencoder\n",
    "autoencoder = Autoencoder(input_dim=28*28, hidden_dim=1024, encoded_dim=4)\n",
    "autoencoder.to(device)\n",
    "\n",
    "# Load pretrained best checkpoint\n",
    "best_autoencoder_ckpt_path = './saved_ckpts/autoencoder/autoencoder_best.pth'\n",
    "autoencoder.load_pretrained_model(model_ckpt_path=best_autoencoder_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EBM\n",
    "energy_model = EnergyNet(in_dim=autoencoder.encoded_dim, autoencoder_ckpt_path=autoencoder.ckpt_path ,hid_dim=8)\n",
    "energy_model.to(device)\n",
    "\n",
    "# Load pretrained best checkpoint\n",
    "best_ebm_ckpt_path = './saved_ckpts/ebm/ebm_best.pth'\n",
    "energy_model.load_pretrained_model(model_ckpt_path=best_ebm_ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________\n",
    "# Autoencoder : Inference\n",
    "Lets first see how the autoencoder performs\n",
    "_________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this after running the Dataset section of train.ipynb\n",
    "X_test   = torch.load('./data/MNIST_binary/X_test.pt').to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass images through autoencoder\n",
    "for idx in range(5):\n",
    "    plot_original_vs_encoded(x=X_test[idx], model=autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________\n",
    "\n",
    "# EBM : Inference\n",
    "Once the autoencoder is ready, we move onto see the results of trained EBM\n",
    "______________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images from energy model\n",
    "generated_images  = energy_model.generate_images(autoencoder=autoencoder, num_images=25, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = energy_model\n",
    "from models.ebm.energy_net_utils import langevin_MCMC\n",
    "X, X_samples = langevin_MCMC(f_theta=self, input_dim=autoencoder.encoded_dim,  \n",
    "                        batch_size=5, num_steps=10000, eps=.001, interval_samples=True)\n",
    "\n",
    "# generated_data = autoencoder.decoder.predict(x_sample.to(device))\n",
    "# generated_data = generated_data.detach().to('cpu')\n",
    "# generated_data = generated_data.reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images_sequence = []\n",
    "\n",
    "for x_sample in  X_samples:\n",
    "\n",
    "    generated_data = autoencoder.decoder.predict(x_sample.to(device))\n",
    "    generated_data = generated_data.detach().to('cpu')\n",
    "    generated_data = generated_data.reshape(-1,28,28)\n",
    "    \n",
    "    generated_images_sequence.append(generated_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the generated images\n",
    "for idx in range(15):\n",
    "    plot_digits(X=generated_images_sequence[idx], Y=None, n=5, random=False)\n",
    "    # Clear the current figure\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ebm.energy_net_utils import langevin_MCMC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the generated images\n",
    "plot_digits(X=generated_images, Y=None, n=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________\n",
    "\n",
    "# THANK YOU\n",
    "_______________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ebm.energy_net_utils import langevin_MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_samples =  langevin_MCMC(f_theta=energy_model, input_dim=autoencoder.encoded_dim,  \n",
    "                              batch_size=5, num_steps=10000, eps=.001, \n",
    "                              interval_samples=True)\n",
    "\n",
    "# generated_data = autoencoder.decoder.predict(x_sample.to(device))\n",
    "# generated_data = generated_data.detach().to('cpu')\n",
    "# generated_data = generated_data.reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samples[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = autoencoder.decoder.predict(X_samples[1].to(device))\n",
    "generated_data = generated_data.detach().to('cpu')\n",
    "generated_data = generated_data.reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X=generated_images, Y=None, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
